# 爬虫服务API化架构改造技术方案

## 新架构技术实现细节

### 核心架构组件
```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  客户端请求   │ → │ Flask API网关 │ → │ Redis消息队列 │
└─────────────┘    └─────────────┘    └─────────────┘
                                                    ↓
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  结果查询     │ ← │  结果存储     │ ← │ 爬虫Worker   │
└─────────────┘    └─────────────┘    └─────────────┘
```

### 1. Flask API网关技术规格
- **框架**: Flask + Redis客户端
- **接口**: RESTful JSON API
- **认证**: 简单的API Key认证
- **限流**: 基于IP的基础限流
- **数据验证**: Pydantic模型验证

### 2. Redis数据结构设计
```python
# 任务队列 (List)
scrape_queue = ["task_id1", "task_id2"]

# 任务详情 (Hash)
task:{task_id} = {
    "urls": "JSON数组",
    "scraper_type": "requests|selenium|...", 
    "status": "pending|processing|completed|failed",
    "created_at": "时间戳",
    "progress": "0-100"
}

# 结果存储 (String, 设置过期时间)
results:{task_id} = "JSON字符串"  # 过期时间: 24小时
```

### 3. 爬虫Worker改造要点
- **输入**: 从Redis读取URL列表，而非文件
- **处理**: 完全复用现有爬虫逻辑
- **输出**: 结果写入Redis，可选保留文件输出用于调试
- **进度上报**: 定期更新任务进度

## 迁移阶段规划

### 阶段1: 基础框架搭建 (Week 1)
**目标**: 建立可运行的基础架构框架

**交付物**:
- Flask API网关基础服务
- Redis容器化部署
- 基础的任务提交/查询API

**验证标准**:
- ✅ API服务可正常启动
- ✅ Redis连接正常
- ✅ 可以提交任务并获得任务ID
- ✅ 可以查询任务状态（返回pending）

**最小实现**:
```python
# 仅实现任务创建和状态查询，Worker暂不处理
@app.route('/api/v1/scrape', methods=['POST'])
def create_task():
    # 验证输入，生成task_id，存储到Redis，返回202
    pass

@app.route('/api/v1/tasks/<task_id>', methods=['GET'])  
def get_task_status(task_id):
    # 从Redis返回任务状态
    pass
```

### 阶段2: 单爬虫Worker集成 (Week 2)
**目标**: 集成一个爬虫类型（如requests）作为验证

**交付物**:
- 改造requests爬虫Worker
- 完整的任务处理流程
- 结果返回机制

**验证标准**:
- ✅ 提交requests爬虫任务后，Worker能正常处理
- ✅ 任务状态能从pending→processing→completed
- ✅ 查询任务能返回正确的爬取结果
- ✅ 错误处理机制正常（失败任务返回错误信息）

**最小实现**:
```python
# Worker核心逻辑（以requests爬虫为例）
def process_task(task_id):
    # 从Redis获取任务详情
    # 调用现有requests_scraper.py逻辑（最小改动）
    # 将结果存储到Redis
    # 更新任务状态
```

### 阶段3: 全爬虫类型支持 (Week 3)
**目标**: 支持所有7种爬虫类型

**交付物**:
- 所有爬虫类型的Worker实现
- 爬虫类型参数验证和路由
- 统一的错误处理

**验证标准**:
- ✅ 所有7种爬虫类型都能正常处理任务
- ✅ 爬虫类型参数验证有效（无效类型返回400）
- ✅ 各爬虫特有的配置正确传递
- ✅ 并发任务处理正常

### 阶段4: 生产环境优化 (Week 4)
**目标**: 性能优化和稳定性提升

**交付物**:
- Docker化部署配置
- 监控和日志系统
- 性能压测报告

**验证标准**:
- ✅ 支持至少10个并发任务处理
- ✅ 单个Worker能稳定运行24小时
- ✅ 内存泄漏检测通过
- ✅ 错误恢复机制正常

## 具体实施步骤

### 阶段1详细任务分解
**Day 1-2: 环境搭建**
- 创建新项目目录结构
- 编写Dockerfile for Flask API
- 配置docker-compose.yml（API + Redis）
- 基础Flask应用框架

**Day 3: API基础实现**
- 实现`POST /api/v1/scrape`接口
- 实现`GET /api/v1/tasks/{id}`接口  
- 基本的请求验证
- Redis连接封装

**Day 4-5: 测试验证**
- 编写API测试用例
- 集成测试环境搭建
- 部署验证

### 阶段2详细任务分解  
**Day 1-2: Worker基础框架**
- 创建Worker容器基础框架
- Redis任务监听机制
- 任务状态更新逻辑

**Day 3-4: 爬虫集成**
- 集成requests爬虫逻辑
- 结果格式标准化
- 错误处理机制

**Day 5: 端到端测试**
- 完整流程测试
- 错误场景测试
- 性能基准测试

### 关键技术决策点

1. **数据序列化**: 使用JSON，保持与现有爬虫输出格式一致
2. **任务去重**: 暂不实现，保持简单性
3. **进度上报**: 基础进度（0%, 50%, 100%），不实时进度
4. **结果过期**: Redis自动过期机制，24小时清理
5. **认证机制**: 简单的API Key，不引入复杂认证系统

## 风险评估与应对

### 技术风险
- **Redis单点故障**: 使用Redis持久化，定期备份
- **Worker崩溃**: 实现任务重试机制（最多3次）
- **内存泄漏**: 定期重启Worker容器（cron job）

### 业务风险  
- **爬虫被封**: 保持现有爬虫的请求频率控制逻辑
- **服务过载**: 基于Redis队列长度的自动限流

## 成功指标

### 功能指标
- 所有现有爬虫功能100%可用
- API响应时间<100ms（任务提交）
- 任务查询响应时间<50ms

### 性能指标  
- 支持并发任务数≥10
- 系统可用性≥99%
- 平均任务处理时间与现有系统相当

### 运维指标
- 部署时间<10分钟
- 监控覆盖率100%
- 日志可追溯性完整

这个改造计划保持了最小可行产品的原则，每个阶段都有明确的交付物和验证标准，确保项目可控可测。