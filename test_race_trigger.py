#!/usr/bin/env python3
"""
ä¸“é—¨æµ‹è¯•ç«é€Ÿæ¨¡å¼è§¦å‘
"""

import requests
import json
import time
import sys
from datetime import datetime

def test_race_trigger():
    """æµ‹è¯•ç«é€Ÿæ¨¡å¼è§¦å‘"""
    base_url = "http://localhost:5000"
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": "demo-api-key-123"
    }
    
    print("ğŸ¯ ä¸“é—¨æµ‹è¯•ç«é€Ÿæ¨¡å¼è§¦å‘")
    print("=" * 60)
    
    # åˆ›å»ºæ›´å®¹æ˜“å¤±è´¥çš„ä»»åŠ¡
    print("ğŸ§ª åˆ›å»ºé«˜å¤±è´¥ç‡æµ‹è¯•ä»»åŠ¡...")
    
    # è¿™äº›URLæ›´å®¹æ˜“å¤±è´¥ï¼Œåº”è¯¥è§¦å‘ç«é€Ÿæ¨¡å¼
    test_urls = [
        "https://httpbin.org/status/404",  # 404é”™è¯¯
        "https://httpbin.org/status/500",  # 500é”™è¯¯
        "https://invalid-domain-xyz123.com", # æ— æ•ˆåŸŸå
        "https://httpbin.org/delay/30",    # è¶…é•¿å»¶è¿Ÿï¼ˆä¼šè¶…æ—¶ï¼‰
        "https://httpbin.org/redirect/10", # è¿‡å¤šé‡å®šå‘
        "https://example.com"              # ä¸€ä¸ªæ­£å¸¸çš„ï¼Œç¡®ä¿è‡³å°‘æœ‰ç‚¹å†…å®¹
    ]
    
    payload = {
        "urls": test_urls,
        "scraper_type": "requests"
    }
    
    try:
        response = requests.post(
            f"{base_url}/api/v1/scrape",
            headers=headers,
            json=payload,
            timeout=10
        )
        
        if response.status_code == 202:
            data = response.json()
            task_id = data["task_id"]
            print(f"âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id}")
            
            # ç­‰å¾…å¹¶ç›‘æ§çŠ¶æ€
            print(f"\nâ³ ç›‘æ§ä»»åŠ¡çŠ¶æ€å˜åŒ–...")
            
            for i in range(60):  # æœ€å¤šç­‰å¾…60ç§’
                try:
                    status_response = requests.get(
                        f"{base_url}/api/v1/tasks/{task_id}",
                        headers=headers,
                        timeout=10
                    )
                    
                    if status_response.status_code == 200:
                        status_data = status_response.json()
                        status = status_data["status"]
                        scraper_type = status_data["scraper_type"]
                        progress = status_data["progress"]
                        
                        print(f"â±ï¸  ç¬¬{i+1}ç§’ - çŠ¶æ€: {status}, ç±»å‹: {scraper_type}, è¿›åº¦: {progress}%")
                        
                        # æ£€æŸ¥æ˜¯å¦è½¬å…¥ç«é€Ÿæ¨¡å¼
                        if scraper_type == "race":
                            print(f"ğŸ‰ æ£€æµ‹åˆ°ç«é€Ÿæ¨¡å¼è§¦å‘ï¼ä»»åŠ¡è½¬å…¥ç«é€Ÿå¤„ç†")
                            
                            # ç­‰å¾…ç«é€Ÿå®Œæˆ
                            for j in range(i+1, 90):  # å†ç­‰å¾…æœ€å¤š30ç§’
                                time.sleep(1)
                                
                                final_response = requests.get(
                                    f"{base_url}/api/v1/tasks/{task_id}",
                                    headers=headers,
                                    timeout=10
                                )
                                
                                if final_response.status_code == 200:
                                    final_data = final_response.json()
                                    final_status = final_data["status"]
                                    
                                    if final_status == "completed":
                                        print(f"âœ… ç«é€Ÿä»»åŠ¡å®Œæˆï¼")
                                        
                                        # è·å–ç»“æœ
                                        result_response = requests.get(
                                            f"{base_url}/api/v1/tasks/{task_id}/results",
                                            headers=headers,
                                            timeout=10
                                        )
                                        
                                        if result_response.status_code == 200:
                                            result_data = result_response.json()
                                            print(f"ğŸ“Š ç«é€Ÿç»“æœ:")
                                            print(f"   æ€»ç»“æœ: {result_data['total_count']}")
                                            print(f"   æˆåŠŸ: {result_data['success_count']}")
                                            print(f"   å¤±è´¥: {result_data['failed_count']}")
                                            
                                            # æ˜¾ç¤ºè·èƒœçˆ¬è™«
                                            if result_data['results']:
                                                winner_scraper = result_data['results'][0].get('scraper_type', 'unknown')
                                                print(f"ğŸ† è·èƒœçˆ¬è™«: {winner_scraper}")
                                            
                                            return True
                                        break
                                    elif final_status == "failed":
                                        print(f"âŒ ç«é€Ÿä»»åŠ¡å¤±è´¥")
                                        return False
                            break
                        elif status in ["completed", "failed"]:
                            print(f"ä»»åŠ¡å®Œæˆï¼ŒçŠ¶æ€: {status}")
                            if status == "completed":
                                print("â„¹ï¸  requestsæˆåŠŸå®Œæˆï¼Œæœªè§¦å‘ç«é€Ÿæ¨¡å¼")
                            return True
                    
                except Exception as e:
                    print(f"çŠ¶æ€æŸ¥è¯¢å¼‚å¸¸: {e}")
                
                time.sleep(1)
            
            print("â° ç­‰å¾…è¶…æ—¶")
            return False
            
        else:
            print(f"âŒ ä»»åŠ¡åˆ›å»ºå¤±è´¥: {response.status_code}")
            print(f"å“åº”: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def test_simple_race():
    """æµ‹è¯•ç®€å•ç«é€Ÿæ¨¡å¼"""
    print("\nğŸš€ æµ‹è¯•ç®€å•ç«é€Ÿæ¨¡å¼")
    
    # åˆ›å»ºä¸€ä¸ªå°ä»»åŠ¡ï¼Œç¡®ä¿requestsä¼šå¤±è´¥
    base_url = "http://localhost:5000"
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": "demo-api-key-123"
    }
    
    # æ‰‹åŠ¨è§¦å‘ç«é€Ÿæ¨¡å¼ - é€šè¿‡ä¿®æ”¹æˆåŠŸç‡é˜ˆå€¼
    test_urls = [
        "https://httpbin.org/status/404",  # ç¡®ä¿å¤±è´¥
        "https://example.com"              # ç¡®ä¿æˆåŠŸ
    ]
    
    payload = {
        "urls": test_urls,
        "scraper_type": "requests"
    }
    
    try:
        response = requests.post(
            f"{base_url}/api/v1/scrape",
            headers=headers,
            json=payload,
            timeout=10
        )
        
        if response.status_code == 202:
            data = response.json()
            task_id = data["task_id"]
            print(f"âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id}")
            
            # è¿™ä¸ªåº”è¯¥æˆåŠŸç‡50%ï¼Œä¼šè§¦å‘ç«é€Ÿæ¨¡å¼ï¼ˆé˜ˆå€¼70%ï¼‰
            print("ğŸ“Š é¢„æœŸï¼š2ä¸ªURLï¼Œ1æˆåŠŸ1å¤±è´¥ = 50%æˆåŠŸç‡ < 70%é˜ˆå€¼ = è§¦å‘ç«é€Ÿæ¨¡å¼")
            
            return task_id
        else:
            print(f"âŒ ä»»åŠ¡åˆ›å»ºå¤±è´¥: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"âŒ åˆ›å»ºå¼‚å¸¸: {e}")
        return None

def main():
    print("ğŸ¯ å¤šçˆ¬è™«ç«é€Ÿæ¨¡å¼è§¦å‘æµ‹è¯•")
    print("=" * 60)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # æµ‹è¯•1ï¼šç®€å•ç«é€Ÿè§¦å‘
    task_id = test_simple_race()
    if task_id:
        print(f"\nâ³ ç­‰å¾…ä»»åŠ¡ {task_id} å®Œæˆ...")
        time.sleep(30)  # ç®€å•ç­‰å¾…
        
        # æ£€æŸ¥ç»“æœ
        base_url = "http://localhost:5000"
        headers = {"X-API-Key": "demo-api-key-123"}
        
        try:
            response = requests.get(f"{base_url}/api/v1/tasks/{task_id}/results", headers=headers)
            if response.status_code == 200:
                data = response.json()
                print(f"ğŸ“Š ç»“æœ: æˆåŠŸ{data['success_count']}/{data['total_count']}")
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç«é€Ÿçˆ¬è™«
                if data['results']:
                    scrapers_used = set(r.get('scraper_type', 'unknown') for r in data['results'])
                    print(f"ğŸ” ä½¿ç”¨çš„çˆ¬è™«ç±»å‹: {scrapers_used}")
            else:
                print(f"âŒ ç»“æœè·å–å¤±è´¥: {response.status_code}")
        except Exception as e:
            print(f"âŒ ç»“æœè·å–å¼‚å¸¸: {e}")
    
    # æµ‹è¯•2ï¼šå¤æ‚ç«é€Ÿè§¦å‘
    print(f"\n" + "="*40)
    test_race_trigger()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ç«é€Ÿæ¨¡å¼æµ‹è¯•å®Œæˆ!")
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

if __name__ == "__main__":
    main()