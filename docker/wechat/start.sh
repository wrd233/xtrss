#!/bin/bash
set -e

# WeChat Scraper å¯åŠ¨è„šæœ¬
# ç»Ÿä¸€çš„ç»“æœå¤„ç†ï¼š/results/wechat/articles/ å’Œ /results/wechat/crawling_report.json

echo "ğŸ’¬ Starting WeChat Scraper..."
echo "Working directory: $(pwd)"

# è®¾ç½®ç»“æœç›®å½•
RESULTS_DIR="/results/wechat"
ARTICLES_DIR="$RESULTS_DIR/articles"

echo "Results directory: $RESULTS_DIR"
echo "Articles directory: $ARTICLES_DIR"

# ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
mkdir -p "$RESULTS_DIR"
mkdir -p "$ARTICLES_DIR"

# æ£€æŸ¥webs.txtæ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "webs.txt" ]; then
    echo "âŒ webs.txt not found!"
    echo "Creating sample webs.txt..."
    cat > webs.txt <<EOF
https://mp.weixin.qq.com/s/lqnPnTC1Ij-m8kqU_dOTKA
https://mp.weixin.qq.com/s/qx3D4yYWLFRANs53yQmQeQ
https://mp.weixin.qq.com/s/9Mnl0uHj5xCzM5rTdItN6Q
https://mp.weixin.qq.com/s/X8GWbx5na254QXPReL3-bg
https://mp.weixin.qq.com/s/bwBZjSsctPRCe6b1xB5nxA
EOF
fi

echo "ğŸ“‹ URLs to scrape:"
cat webs.txt
echo ""

# å¯åŠ¨Chromeæµè§ˆå™¨æœåŠ¡
echo "ğŸ”„ Starting Chrome browser service..."
# å¯åŠ¨Xvfbè™šæ‹Ÿæ˜¾ç¤ºï¼ˆå¦‚æœéœ€è¦ï¼‰
if command -v Xvfb > /dev/null 2>&1; then
    echo "Starting Xvfb virtual display..."
    Xvfb :99 -ac -screen 0 1280x1024x24 &
    export DISPLAY=:99
    sleep 2
fi

# ç­‰å¾…seleniumæœåŠ¡å‡†å¤‡å°±ç»ª
echo "â³ Waiting for Selenium service to be ready..."
sleep 5

# è¿è¡Œçˆ¬è™«å¹¶æ•è·è¾“å‡º
echo "ğŸš€ Starting scraping process..."
if python3 wechat_scraper.py; then
    echo "âœ… Scraping completed successfully!"
    
    # æ£€æŸ¥ç»“æœæ˜¯å¦ç”Ÿæˆåœ¨wechat_resultsç›®å½•
    if [ -d "wechat_results" ]; then
        echo "ğŸ“ Moving results to unified directory structure..."
        
        # ç§»åŠ¨æ–‡ç« æ–‡ä»¶åˆ°ç»Ÿä¸€çš„articlesç›®å½•
        if [ -d "wechat_results/articles" ]; then
            cp -r wechat_results/articles/* "$ARTICLES_DIR/" 2>/dev/null || true
        fi
        
        # å¤åˆ¶çˆ¬å–æŠ¥å‘Š
        if [ -f "wechat_results/crawling_report.json" ]; then
            cp "wechat_results/crawling_report.json" "$RESULTS_DIR/"
            echo "ğŸ“Š Report saved to: $RESULTS_DIR/crawling_report.json"
        fi
        
        # å¤åˆ¶å…¶ä»–ç»“æœæ–‡ä»¶
        if ls wechat_results/*.json 1> /dev/null 2>&1; then
            cp wechat_results/*.json "$ARTICLES_DIR/" 2>/dev/null || true
        fi
        
        echo "âœ… Results organized in unified structure:"
        echo "  ğŸ“ Articles: $ARTICLES_DIR"
        echo "  ğŸ“Š Report: $RESULTS_DIR/crawling_report.json"
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if [ -f "$RESULTS_DIR/crawling_report.json" ]; then
            echo ""
            echo "ğŸ“ˆ Scraping Statistics:"
            if command -v python3 > /dev/null 2>&1; then
                python3 -c "
import json
import os
report_path = '$RESULTS_DIR/crawling_report.json'
if os.path.exists(report_path):
    with open(report_path, 'r', encoding='utf-8') as f:
        report = json.load(f)
    metadata = report.get('metadata', {})
    print(f\"Total URLs: {metadata.get('total_urls', 'N/A')}\")
    print(f\"Successful: {metadata.get('successful_scrapes', 'N/A')}\")
    print(f\"Failed: {metadata.get('failed_scrapes', 'N/A')}\")
    if metadata.get('total_urls', 0) > 0:
        success_rate = (metadata.get('successful_scrapes', 0) / metadata.get('total_urls', 1)) * 100
        print(f\"Success Rate: {success_rate:.1f}%\")
"
            fi
        fi
        
    else
        echo "âš ï¸  No results directory found, but scraping completed."
    fi
    
else
    echo "âŒ Scraping failed!"
    exit 1
fi

# æ¸…ç†Chromeè¿›ç¨‹
echo "ğŸ§¹ Cleaning up Chrome processes..."
pkill -f chrome || true
pkill -f chromedriver || true
pkill -f Xvfb || true

echo ""
echo "ğŸ‰ WeChat scraper finished! Check results in:"
echo "   ğŸ“ $RESULTS_DIR"
echo "   ğŸ“„ $RESULTS_DIR/crawling_report.json"
echo "   ğŸ“‚ $ARTICLES_DIR"