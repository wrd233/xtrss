{
  "title": "",
  "description": "真正的“数字人”不应只是声音与动作的机械复现，更应具备情感理解、个性表达与智能交互的能力。",
  "content": "字节OmniHuman 1.5发布：AI数字人首次实现“双人对戏”，语音驱动表情动作，全网刷屏！ Original 戴戴相传 私域X星球 由于AI的不断发展与进化，数字人产品现在可谓是多的数不胜数，但数字人模型的表现力往往都停留在最基本的只能生成流畅的人物动作和克隆声音。 然而，真正的“数字人”不应只是声音与动作的机械复现，更应具备情感理解、个性表达与智能交互的能力。 于是，字节跳动数字人团队近期推出了新一代AI视频生成模型OmniHuman-1.5，作为OmniHuman-1的升级版本，它不仅延续了“单张图像+一段音频”生成高质量人物视频的核心能力，更在真实感、情感表现与多人交互等方面实现了跨越式进步，被业内誉为“AI视频生成的新天花板”。 标志着数字人技术正式迈入“多模态情感化”新阶段！ 与传统仅支持语音驱动和简单肢体动作生成的系统相比，OmniHuman-1.5在多个维度实现了跨越。 OmniHuman-1.5实现了业界领先的“双人音频驱动”功能。传统AI视频生成大多局限于单人场景，而该模型能够同时处理两段语音输入，精准捕捉角色之间的互动表情与动作响应。这一突破为对话类视频、虚拟访谈甚至微剧情表演打开了全新的创作空间。 它不仅能够精准还原口型与表情，更实现了从“说得好”到“演得像”的质变——通过对语音情绪进行实时解析与反馈，生成与之匹配的表情与肢体语言，使虚拟角色具备情绪感染力。 其突破性的双人交互生成能力，使数字人不再局限于“自言自语”，而能够实现多角色间的自然对话与互动，极大拓展了虚拟内容的生产边界。 在功能扩展方面，OmniHuman-1.5支持通过文本提示词对生成内容进行风格化设定与动作指导，体现出“生成式AI”与“控制性创作”结合的新思路。这一功能降低了专业视频制作的门槛，使创作者能够更自由地设计角色行为与场景氛围，实现更具叙事性的视觉内容生成。 OmniHuman-1.5最大亮点在于其出色的多模态融合与运动控制能力。借助优化后的多模态运动条件混合训练策略，该系统在口型同步、微表情刻画和肢体动作的自然度方面表现尤为细腻。 无论是真人还是动漫形象，生成的角色动态与语音内容高度吻合，几乎达到以假乱真的视觉效果。 在生成长视频方面，OmniHuman-1.5通过帧间连接策略，确保一分钟以上视频在时序上的连贯性与角色身份的一致性。这意味着用户已可将其用于生成演讲视频、音乐MV甚至短剧内容，极大拓展了商用可能性。 除了技术性能的提升，OmniHuman-1.5还展现出一定程度的“情感智能”。系统能够解析语音中的情绪变化，并自动驱动人物做出相应的表情与肢体反应。同时，新加入的文本提示词功能允许用户通过自然语言进一步控制视频风格、场景设定或动作细节，显著提高了创作的灵活度。 OmniHuman-1.5使用地址： https://omnihuman-lab.github.io/v1_5 尽管目前AI数字人仍面临动作自然性、物理真实感及算力需求等方面的挑战，OmniHuman-1.5所代表的技术方向已明确指向下一代数字人的核心能力：情感化、交互化、跨模态可控化。 它不仅可用于虚拟偶像、社交娱乐、智能导览等场景，更可能成为人机交互的新界面，重塑虚拟制作、沉浸教学乃至元宇宙基础内容的生成方式。 未来，随着语音理解、情绪计算与图形生成模型的进一步融合，数字人将不再是没有温度的“音画工具”，而成为具备人格化特征、可情感交互的数字化存在。OmniHuman-1.5正是这一演进之路上令人瞩目的里程碑。 · 扫码加入「戴戴相传AI交流群」 · 专注 AIGC 工具&数字人打造自媒体 · 分享最新AI变现案例 | AI实时热点资讯 · 带你了解AI，学习AI，掌握AI 预览时标签不可点 Scan to Follow 继续滑动看下一个 轻触阅读原文 私域X星球 向上滑动看下一个 Got It Scan with Weixin to use this Mini Program Cancel Allow Cancel Allow Cancel Allow × 分析 微信扫一扫可打开此内容， 使用完整服务 : ， ， ， ， ， ， ， ， ， ， ， ， . Video Mini Program Like ，轻点两下取消赞 Wow ，轻点两下取消在看 Share Comment Favorite 听过",
  "method": "requests_beautifulsoup",
  "status_code": 200,
  "success": true
}